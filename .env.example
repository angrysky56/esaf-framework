# ESAF Framework - Environment Configuration
# Copy this file to .env and configure your settings

# ===========================================
# LLM PROVIDER CONFIGURATION
# ===========================================

# Default LLM provider to use (google-genai, openai, anthropic, ollama, lm-studio)
VITE_DEFAULT_LLM_PROVIDER=google-genai

# ===========================================
# GOOGLE GENERATIVE AI (GEMINI)
# ===========================================
# Get your API key from: https://aistudio.google.com/apikey
VITE_GOOGLE_GENAI_API_KEY=your_gemini_api_key_here

# Available Gemini models:
# - gemini-1.5-pro (recommended for complex analysis)
# - gemini-1.5-flash (faster, good for simple tasks)
# - gemini-pro-vision (for image analysis)
VITE_GOOGLE_GENAI_MODEL=gemini-2.0-flash
VITE_GOOGLE_GENAI_TEMPERATURE=0.7
VITE_GOOGLE_GENAI_MAX_TOKENS=8164

# ===========================================
# OPENAI (GPT MODELS)
# ===========================================
# Get your API key from: https://platform.openai.com/api-keys
VITE_OPENAI_API_KEY=your_openai_api_key_here
VITE_OPENAI_BASE_URL=https://api.openai.com/v1

# Available OpenAI models:
# - gpt-4o (latest GPT-4 optimized)
# - gpt-4-turbo (fast and capable)
# - gpt-3.5-turbo (cost-effective)
VITE_OPENAI_MODEL=gpt-4-nano
VITE_OPENAI_TEMPERATURE=0.7
VITE_OPENAI_MAX_TOKENS=8164

# ===========================================
# ANTHROPIC (CLAUDE MODELS)
# ===========================================
# Get your API key from: https://console.anthropic.com/
VITE_ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Available Claude models:
# - claude-sonnet-4-20250514 (latest Claude Sonnet 4)
# - claude-opus-4 (most capable, slower)
# - claude-haiku-4 (fastest, for simple tasks)
VITE_ANTHROPIC_MODEL=claude-sonnet-4-20250514
VITE_ANTHROPIC_TEMPERATURE=0.7
VITE_ANTHROPIC_MAX_TOKENS=8164

# ===========================================
# OLLAMA (LOCAL MODELS)
# ===========================================
# Ollama server configuration
VITE_OLLAMA_BASE_URL=http://localhost:11434
VITE_OLLAMA_MODEL=qwen3

# Alternative models you can pull with 'ollama pull':
# - llama3.2:latest (8B, good balance)
# - llama3.2:70b (larger, more capable)
# - mistral:latest (7B, fast)
# - codellama:latest (code-focused)
# - phi3:latest (small, efficient)
# - qwen3 (multilingual)

VITE_OLLAMA_TEMPERATURE=0.7
VITE_OLLAMA_MAX_TOKENS=8164
VITE_OLLAMA_TIMEOUT=30000

# ===========================================
# LM STUDIO (LOCAL SERVER)
# ===========================================
# LM Studio server configuration (uses OpenAI-compatible API)
VITE_LM_STUDIO_BASE_URL=http://localhost:1234/v1
VITE_LM_STUDIO_API_KEY=lm-studio

# Model name as configured in LM Studio
# This should match the model you've loaded in LM Studio
VITE_LM_STUDIO_MODEL=qwen3-4b-128k

VITE_LM_STUDIO_TEMPERATURE=0.7
VITE_LM_STUDIO_MAX_TOKENS=8164
VITE_LM_STUDIO_TIMEOUT=30000

# ===========================================
# AGENT-SPECIFIC CONFIGURATIONS
# ===========================================

# Data Analysis Agent settings
VITE_DA_AGENT_LLM_PROVIDER=google-genai
VITE_DA_AGENT_SYSTEM_PROMPT="You are a specialized Data Analysis Agent in the ESAF framework. Your role is to analyze data using Bayesian probabilistic methods, detect anomalies, extract features, and validate data sources. Always provide confidence scores and detailed reasoning for your analysis."

# Optimization Agent settings
VITE_OA_AGENT_LLM_PROVIDER=google-genai
VITE_OA_AGENT_SYSTEM_PROMPT="You are an Optimization Agent specializing in constraint formulation and algorithm selection. Use linear programming principles and genetic algorithms to find optimal solutions."

# Game Theory Agent settings
VITE_GT_AGENT_LLM_PROVIDER=google-genai
VITE_GT_AGENT_SYSTEM_PROMPT="You are a Game Theory Agent focused on strategy formulation, conflict resolution, and risk assessment. Apply Nash equilibrium and cooperative game theory principles."

# Swarm Intelligence Agent settings
VITE_SI_AGENT_LLM_PROVIDER=google-genai
VITE_SI_AGENT_SYSTEM_PROMPT="You are a Swarm Intelligence Agent specializing in adaptability, learning, and learning rate control. Use swarm intelligence principles to optimize system performance."

# Decision Making Agent settings
VITE_DM_AGENT_LLM_PROVIDER=google-genai
VITE_DM_AGENT_SYSTEM_PROMPT="You are a Decision Making Agent focused on decision integration, contingency planning, and fallback strategies. Use multi-criteria decision analysis to provide optimal solutions."

# ===========================================
# FRAMEWORK SETTINGS
# ===========================================

# Maximum concurrent LLM requests
VITE_MAX_CONCURRENT_LLM_REQUESTS=10

# Request timeout in milliseconds
VITE_LLM_REQUEST_TIMEOUT=60000

# Enable request caching to reduce API costs
VITE_ENABLE_LLM_CACHING=true

# Cache duration in milliseconds (1 hour default)
VITE_LLM_CACHE_DURATION=3600000

# Enable detailed logging for LLM interactions
VITE_LLM_DEBUG_LOGGING=false

# ===========================================
# DEVELOPMENT SETTINGS
# ===========================================

# Set to 'development' for detailed logs
NODE_ENV=development

# Enable mock responses for testing without API calls
VITE_MOCK_LLM_RESPONSES=false

# Delay for mock responses (milliseconds)
VITE_MOCK_RESPONSE_DELAY=1000
